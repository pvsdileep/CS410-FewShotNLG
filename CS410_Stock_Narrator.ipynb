{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "from simplenlg.features      import Feature, Tense, InternalFeature, NumberAgreement, Person\n",
    "from simplenlg.framework     import DocumentElement, InflectedWordElement, LexicalCategory\n",
    "from simplenlg.framework     import NLGElement, NLGFactory, StringElement, WordElement\n",
    "from simplenlg.lexicon       import Lexicon, XMLLexicon\n",
    "from simplenlg.phrasespec    import *\n",
    "from simplenlg.realiser.english  import Realiser\n",
    "from collections import OrderedDict\n",
    "import inflect\n",
    "import statistics\n",
    "import random\n",
    "import csv\n",
    "import locale\n",
    "import math\n",
    "import datamuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataType = Enum('DataTypes', 'percent dollar number date string')\n",
    "PeriodType = Enum('PeriodType', 'day week month quarter')\n",
    "\n",
    "\n",
    "class Human():\n",
    "    def get_positive(self):\n",
    "        arr = ['yes', 'great', 'nice', 'awesome', 'good', 'wonderful']\n",
    "        return arr[random.randint(0, len(arr)-1)].capitalize()\n",
    "\n",
    "    def get_negative(self):\n",
    "        arr = ['not good', 'oh no', 'i see', 'okay']\n",
    "        return arr[random.randint(0, len(arr)-1)].capitalize()\n",
    "    \n",
    "    def get_neutral(self):\n",
    "        arr = ['not bad!', 'Think about it!']\n",
    "        return arr[random.randint(0, len(arr)-1)].capitalize()\n",
    "\n",
    "    def get_greetings(self):\n",
    "        arr = ['hey', 'hi', \"how is it going\",\n",
    "               'how are you doing', \"how is everything\", 'good day']\n",
    "        return arr[random.randint(0, len(arr)-1)].capitalize()\n",
    "\n",
    "    def get_fill(self):\n",
    "        arr = ['We found out', 'We noticed',\n",
    "               'We observed', 'We discovered']\n",
    "        return arr[random.randint(0, len(arr)-1)].capitalize()\n",
    "\n",
    "    def get_discovered(self):\n",
    "        arr = ['started looking at', 'looked into', 'looked at', 'dug into']\n",
    "        return arr[random.randint(0, len(arr)-1)].capitalize()\n",
    "\n",
    "    def get_period(self):\n",
    "        arr = ['this week', 'this period',\n",
    "               'so far this week', 'so far this period', '']\n",
    "        return arr[random.randint(0, len(arr)-1)].capitalize()\n",
    "\n",
    "    def get_lets_see(self):\n",
    "        arr = ['']\n",
    "        return arr[random.randint(0, len(arr)-1)].capitalize()\n",
    "\n",
    "    def get_more(self):\n",
    "        arr = ['Interested to know more?', 'Here are few more quick facts for you!...',\n",
    "               'Still hungry for numbers?']\n",
    "        return arr[random.randint(0, len(arr)-1)].capitalize()\n",
    "    \n",
    "    def get_lets_look_at(self):\n",
    "        arr = ['Lets look at']\n",
    "        return arr[random.randint(0, len(arr)-1)].capitalize()\n",
    "\n",
    "    def get_direction(self, num):\n",
    "        if(float(num) > 0):\n",
    "            return \"\\'up\\'\"\n",
    "        else:\n",
    "            return \"\\'down\\'\"\n",
    "\n",
    "\n",
    "class Period():\n",
    "\n",
    "    def __init__(self, start_date, end_date, period_type=PeriodType.week):\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.period_type = period_type\n",
    "\n",
    "    def get_period_str(self):\n",
    "        if PeriodType.day:\n",
    "            return 'daily'\n",
    "        elif PeriodType.week:\n",
    "            return 'weekly'\n",
    "        elif PeriodType.month:\n",
    "            return 'monthly'\n",
    "        elif PeriodType.quarter:\n",
    "            return 'quarterly'\n",
    "\n",
    "class StockDataDict():\n",
    "\n",
    "    def __init__(self, symbol=\"symbol\", last_week_close_price=\"\", start_ts=\"\", end_ts=\"\", curr_period_avg=\"\", \n",
    "                 curr_period_min=\"\", curr_period_max=\"\", curr_period_var=\"\", numeric_units=\"\", company=\"company\", \n",
    "                 hq=\"HQ\", domain=\"domain\"):\n",
    "        self.symbol = symbol\n",
    "        self.last_week_close_price = last_week_close_price\n",
    "        self.start_ts = start_ts\n",
    "        self.end_ts = end_ts\n",
    "        self.curr_period_avg = curr_period_avg\n",
    "        self.curr_period_min = curr_period_min\n",
    "        self.curr_period_max = curr_period_max\n",
    "        self.curr_period_var = curr_period_var\n",
    "        self.numeric_units = numeric_units\n",
    "        self.company = company\n",
    "        self.hq = hq\n",
    "        self.domain = domain\n",
    "        #self.period = \"period\" #calculate period based on start and end ts\n",
    "        #self.key_units = key_units\n",
    "        #self.measure = measure\n",
    "        #self.measure_scale = measure_scale\n",
    "        #self.convert_keys()\n",
    "        #self.prev_data_dict = prev_data_dict\n",
    "        #if prev_data_dict:\n",
    "        #    self.compare_to_previous()\n",
    "\n",
    "    def data_to_text_conversion_str(self, val):\n",
    "        if(self.numeric_units == DataType.percent):\n",
    "            return self.format_percent_str(val)\n",
    "        elif (self.numeric_units == DataType.dollar):\n",
    "            return self.convert_to_dollars_str(val)\n",
    "        elif (self.numeric_units == DataType.number):\n",
    "            return self.format_int_str(val)\n",
    "        else:\n",
    "            return val\n",
    "\n",
    "    def data_to_text_conversion_val(self, val):\n",
    "        return val\n",
    "\n",
    "    def format_percent_str(self, percent_change, percentSign=True):\n",
    "        return str(abs(round(percent_change, 2)))+\"%\"\n",
    "    \n",
    "    def format_int_str(self, val):\n",
    "        return str(int(val))\n",
    "\n",
    "    def convert_to_dollars_str(self, dollars):\n",
    "        locale.setlocale(locale.LC_ALL, '')\n",
    "        return locale.currency(dollars)\n",
    "\n",
    "\n",
    "class Narrator():\n",
    "    def __init__(self, period):\n",
    "        self.period = period\n",
    "        self.lexicon = XMLLexicon()\n",
    "        self.nlgFactory = NLGFactory(self.lexicon)\n",
    "        self.realiser = Realiser(self.lexicon)\n",
    "        self.inflect_engine = inflect.engine()\n",
    "\n",
    "    def format_percent(self, percent_change, percentSign=True):\n",
    "        if(not percentSign):\n",
    "            return \"{0:.0}\".format(percent_change)\n",
    "        return \"{0:.0%}\".format(percent_change)\n",
    "\n",
    "    def get_last(self, period_type):\n",
    "        return {\n",
    "            'day': 'yesterday',\n",
    "            'week': 'last week',\n",
    "            'month': 'last month',\n",
    "            'quarter': 'last quarter',\n",
    "        }[period_type]\n",
    "\n",
    "    def reltime(self, date, compare_to=None, at='@'):\n",
    "        r'''Takes a datetime and returns a relative representation of the\n",
    "        time.\n",
    "        :param date: The date to render relatively\n",
    "        :param compare_to: what to compare the date to. Defaults to datetime.now()\n",
    "        :param at: date/time separator. defaults to \"@\". \"at\" is also reasonable.\n",
    "        >>> from datetime import datetime, timedelta\n",
    "        >>> today = datetime(2050, 9, 2, 15, 00)\n",
    "        >>> earlier = datetime(2050, 9, 2, 12)\n",
    "        >>> reltime(earlier, today)\n",
    "        'today @ 12pm'\n",
    "        >>> yesterday = today - timedelta(1)\n",
    "        >>> reltime(yesterday, compare_to=today)\n",
    "        'yesterday @ 3pm'\n",
    "        >>> reltime(datetime(2050, 9, 1, 15, 32), today)\n",
    "        'yesterday @ 3:32pm'\n",
    "        >>> reltime(datetime(2050, 8, 31, 16), today)\n",
    "        'Wednesday @ 4pm (2 days ago)'\n",
    "        >>> reltime(datetime(2050, 8, 26, 14), today)\n",
    "        'last Friday @ 2pm (7 days ago)'\n",
    "        >>> reltime(datetime(2049, 9, 2, 12, 00), today)\n",
    "        'September 2nd, 2049 @ 12pm (last year)'\n",
    "        >>> today = datetime(2012, 8, 29, 13, 52)\n",
    "        >>> last_mon = datetime(2012, 8, 20, 15, 40, 55)\n",
    "        >>> reltime(last_mon, today)\n",
    "        'last Monday @ 3:40pm (9 days ago)'\n",
    "        '''\n",
    "        def ordinal(n):\n",
    "            r'''Returns a string ordinal representation of a number\n",
    "            Taken from: http://stackoverflow.com/a/739301/180718\n",
    "            '''\n",
    "            if 10 <= n % 100 < 20:\n",
    "                return str(n) + 'th'\n",
    "            else:\n",
    "                return str(n) + {1 : 'st', 2 : 'nd', 3 : 'rd'}.get(n % 10, \"th\")\n",
    "\n",
    "        compare_to = compare_to or datetime.now()\n",
    "        if date > compare_to:\n",
    "            return NotImplementedError('reltime only handles dates in the past')\n",
    "        #get timediff values\n",
    "        diff = compare_to - date\n",
    "        if diff.seconds < 60 * 60 * 8: #less than a business day?\n",
    "            days_ago = diff.days\n",
    "        else:\n",
    "            days_ago = diff.days + 1\n",
    "        months_ago = compare_to.month - date.month\n",
    "        years_ago = compare_to.year - date.year\n",
    "        weeks_ago = int(math.ceil(days_ago / 7.0))\n",
    "        #get a non-zero padded 12-hour hour\n",
    "        hr = date.strftime('%I')\n",
    "        if hr.startswith('0'):\n",
    "            hr = hr[1:]\n",
    "        wd = compare_to.weekday()\n",
    "        #calculate the time string\n",
    "        if date.minute == 0:\n",
    "            time = '{0}{1}'.format(hr, date.strftime('%p').lower())\n",
    "        else:\n",
    "            time = '{0}:{1}'.format(hr, date.strftime('%M%p').lower())\n",
    "        #calculate the date string\n",
    "        if days_ago == 0:\n",
    "            #datestr = 'today {at} {time}'\n",
    "            datestr = 'today'\n",
    "        elif days_ago == 1:\n",
    "            #datestr = 'yesterday {at} {time}'\n",
    "            datestr = 'yesterday'\n",
    "        elif (wd in (5, 6) and days_ago in (wd+1, wd+2)) or \\\n",
    "                wd + 3 <= days_ago <= wd + 8:\n",
    "            #this was determined by making a table of wd versus days_ago and\n",
    "            #divining a relationship based on everyday speech. This is somewhat\n",
    "            #subjective I guess!\n",
    "            #datestr = 'last {weekday} {at} {time} ({days_ago} days ago)'\n",
    "            datestr = 'last {weekday} {days_ago} days ago'\n",
    "        elif days_ago <= wd + 2:\n",
    "            #datestr = '{weekday} {at} {time} ({days_ago} days ago)'\n",
    "            datestr = '{weekday} {days_ago} days ago'\n",
    "        elif years_ago == 1:\n",
    "            #datestr = '{month} {day}, {year} {at} {time} (last year)'\n",
    "            datestr = '{month} last year'\n",
    "        elif years_ago > 1:\n",
    "            #datestr = '{month} {day}, {year} {at} {time} ({years_ago} years ago)'\n",
    "            datestr = '{month} {years_ago} years ago'\n",
    "        elif months_ago == 1:\n",
    "            #datestr = '{month} {day} {at} {time} (last month)'\n",
    "            datestr = 'last month'\n",
    "        elif months_ago > 1:\n",
    "            #datestr = '{month} {day} {at} {time} ({months_ago} months ago)'\n",
    "            datestr = '{months_ago} months ago'\n",
    "        else: \n",
    "            #not last week, but not last month either\n",
    "            #datestr = '{month} {day} {at} {time} ({days_ago} days ago)'\n",
    "            datestr = '{days_ago} days ago'\n",
    "            \n",
    "        #return datestr\n",
    "        return datestr.format(time=time,\n",
    "                              weekday=date.strftime('%A'),\n",
    "                              day=ordinal(date.day),\n",
    "                              days=diff.days,\n",
    "                              days_ago=days_ago,\n",
    "                              month=date.strftime('%B'),\n",
    "                              years_ago=years_ago,\n",
    "                              months_ago=months_ago,\n",
    "                              weeks_ago=weeks_ago,\n",
    "                              year=date.year,\n",
    "                              at=at)\n",
    "    \n",
    "    def add_metric_chart(self, period_value, last_period_value, subject, value_title, numeric_units=DataType.number, period_overwrite=None, given_delta=None):\n",
    "        segments = [{}]\n",
    "        percent_change = 0\n",
    "        try:\n",
    "            percent_change = ((float(period_value)-float(last_period_value)) /\n",
    "                              float(last_period_value)) if not given_delta else given_delta\n",
    "        except ZeroDivisionError as e:\n",
    "            pass\n",
    "        direction_change = Human().get_direction(percent_change)\n",
    "        period = self.period.period_type.name.lower(\n",
    "        ) if not period_overwrite else period_overwrite\n",
    "        direction_str = Human().get_direction(percent_change).replace('\\'', '')\n",
    "        percent_change_str = self.format_percent(abs(percent_change))\n",
    "        period_value_str = StockDataDict(\n",
    "            numeric_units=numeric_units).data_to_text_conversion_str(period_value)\n",
    "\n",
    "        # https://github.com/bjascob/pySimpleNLG/blob/02db3ea1fc1d210c24c3046cd79384ede0fe8be9/tests/syntax/english/ClauseTest.py\n",
    "\n",
    "        x_is_up = self.nlgFactory.createClause()\n",
    "        x_is_up.setFeature(Feature.TENSE, Tense.PAST)\n",
    "        x_is_up.setSubject(f\"{value_title}\")\n",
    "        if not self.inflect_engine.singular_noun(value_title):\n",
    "            x_is_up.setFeature(Feature.NUMBER, NumberAgreement.SINGULAR)\n",
    "        else:\n",
    "            x_is_up.setFeature(Feature.NUMBER, NumberAgreement.PLURAL)\n",
    "        x_is_up.setVerb(\"be\")\n",
    "        x_is_up.setObject(self.nlgFactory.createNounPhrase(direction_str))\n",
    "        x_is_up_str = self.realiser.realise(x_is_up).getRealisation()\n",
    "\n",
    "        current_period = self.nlgFactory.createClause()\n",
    "        current_period.setFeature(Feature.TENSE, Tense.PAST)\n",
    "        current_period.setSubject(f\"{value_title}\")\n",
    "        if not self.inflect_engine.singular_noun(value_title):\n",
    "            current_period.setFeature(Feature.NUMBER, NumberAgreement.SINGULAR)\n",
    "        else:\n",
    "            current_period.setFeature(Feature.NUMBER, NumberAgreement.PLURAL)\n",
    "        current_period.setVerb(\"be\")\n",
    "        current_period.setObject(str(period_value_str))\n",
    "        current_period = self.realiser.realise(current_period).getRealisation()\n",
    "\n",
    "        steps = [f\"{subject}\"]\n",
    "        steps.append(\n",
    "            f\"{current_period} this {period}.\"\n",
    "        )\n",
    "        if(percent_change != 0):\n",
    "            steps.append(\n",
    "                f\"{x_is_up_str} by {percent_change_str} from {self.get_last(period)}'s {str(last_period_value)}.\")\n",
    "        return steps\n",
    "\n",
    "    def add_line_chart(self, entity1, entity2, subject, value_title, value1, value2, numeric_units=DataType.number):\n",
    "        percent_change = 0\n",
    "        try:\n",
    "            percent_change = ((float(value1)-float(value2)) /\n",
    "                              float(value2))\n",
    "        except ZeroDivisionError as e:\n",
    "            pass\n",
    "        direction_change = Human().get_direction(percent_change)\n",
    "        direction_str = Human().get_direction(percent_change).replace('\\'', '')\n",
    "        percent_change_str = self.format_percent(abs(percent_change))\n",
    "        #period_value_str = DataDict(\n",
    "        #    numeric_units=numeric_units).data_to_text_conversion_str(period_value)\n",
    "\n",
    "        # https://github.com/bjascob/pySimpleNLG/blob/02db3ea1fc1d210c24c3046cd79384ede0fe8be9/tests/syntax/english/ClauseTest.py\n",
    "\n",
    "        x_is_up = self.nlgFactory.createClause()\n",
    "        x_is_up.setFeature(Feature.TENSE, Tense.PAST)\n",
    "        x_is_up.setSubject(f\"{entity1}'s {value_title}\")\n",
    "        if not self.inflect_engine.singular_noun(value_title):\n",
    "            x_is_up.setFeature(Feature.NUMBER, NumberAgreement.SINGULAR)\n",
    "        else:\n",
    "            x_is_up.setFeature(Feature.NUMBER, NumberAgreement.PLURAL)\n",
    "        x_is_up.setVerb(\"be\")\n",
    "        x_is_up.setObject(self.nlgFactory.createNounPhrase(direction_str))\n",
    "        x_is_up_str = self.realiser.realise(x_is_up).getRealisation()\n",
    "        \n",
    "        steps = [f\"{subject}\"]\n",
    "        api = datamuse.Datamuse()\n",
    "        \n",
    "        #dm_tried = [{'word':'tried'}]\n",
    "        #dm_tried.extend(api.words(ml='tried', max=10))\n",
    "        dm_tried = [{'word': 'tried'}, {'word': 'proved', 'score': 84677, 'tags': ['syn', 'adj']}, {'word': 'tested', 'score': 84208, 'tags': ['syn', 'adj']}, {'word': 'proven', 'score': 82470, 'tags': ['syn', 'adj']}, {'word': 'dependable', 'score': 78926, 'tags': ['syn', 'adj']}, {'word': 'reliable', 'score': 78581, 'tags': ['syn', 'adj']}, {'word': 'time-tested', 'score': 77429, 'tags': ['syn', 'adj']}, {'word': 'tried and true', 'score': 77429, 'tags': ['syn', 'adj']}, {'word': 'well-tried', 'score': 77429, 'tags': ['syn', 'adj']}, {'word': 'attempted', 'score': 77428, 'tags': ['adj', 'v']}, {'word': 'wanted', 'score': 71929, 'tags': ['adj', 'v']}]\n",
    "        sel_tried = dm_tried[random.randint(0, len(dm_tried)-1)]\n",
    "\n",
    "        #dm_comparative = [{'word':'comparative'}]\n",
    "        #dm_comparative.extend(api.words(ml='comparative', max=10))\n",
    "        dm_comparative = [{'word': 'comparative'}, {'word': 'relative', 'score': 83552, 'tags': ['syn', 'adj']}, {'word': 'comparison', 'score': 69209, 'tags': ['n']}, {'word': 'comparable', 'score': 68893, 'tags': ['adj']}, {'word': 'comparability', 'score': 67606, 'tags': ['n']}, {'word': 'comparing', 'score': 67268, 'tags': ['n']}, {'word': 'comparisons', 'score': 66205, 'tags': ['n']}, {'word': 'compare', 'score': 65949, 'tags': ['v']}, {'word': 'benchmarking', 'score': 65282, 'tags': ['adj']}, {'word': 'compared', 'score': 64795, 'tags': ['v']}, {'word': 'corresponding', 'score': 64091, 'tags': ['adj']}]\n",
    "        sel_comparative = dm_comparative[random.randint(0, len(dm_comparative)-1)]\n",
    "\n",
    "        #dm_study = [{'word':'study'}]\n",
    "        #dm_study.extend(api.words(ml='study', max=10))\n",
    "        dm_study = [{'word': 'study'}, {'word': 'survey', 'score': 96232, 'tags': ['syn', 'n']}, {'word': 'report', 'score': 89437, 'tags': ['syn', 'n']}, {'word': 'examine', 'score': 85312, 'tags': ['syn', 'v']}, {'word': 'work', 'score': 82653, 'tags': ['syn', 'n']}, {'word': 'analyze', 'score': 81788, 'tags': ['syn', 'v']}, {'word': 'meditate', 'score': 80487, 'tags': ['syn', 'v']}, {'word': 'learn', 'score': 79066, 'tags': ['syn', 'v']}, {'word': 'consider', 'score': 78968, 'tags': ['syn', 'v']}, {'word': 'analyse', 'score': 77657, 'tags': ['syn', 'v']}, {'word': 'sketch', 'score': 77583, 'tags': ['syn', 'n']}]\n",
    "        sel_study = dm_study[random.randint(0, len(dm_study)-1)]\n",
    "        \n",
    "        steps.append(\n",
    "            f\"We {sel_tried['word']} to do a {sel_comparative['word']} {sel_study['word']} of {entity1} with {entity2}.\"\n",
    "        )\n",
    "        \n",
    "        #dm_compared = [{'word':'compared'}]\n",
    "        #dm_compared.extend(api.words(ml='compared', max=10))\n",
    "        dm_compared = [{'word': 'compared'}, {'word': 'versus', 'score': 70844, 'tags': ['n', 'v']}, {'word': 'comparison', 'score': 70308, 'tags': ['n']}, {'word': 'contrasted', 'score': 68805, 'tags': ['v']}, {'word': 'equated', 'score': 66307, 'tags': ['v']}, {'word': 'comparative', 'score': 64868, 'tags': ['adj', 'n']}, {'word': 'matched', 'score': 62311, 'tags': ['adj', 'v']}, {'word': 'relative', 'score': 62259, 'tags': ['adj']}, {'word': 'comparisons', 'score': 61965, 'tags': ['n']}, {'word': 'measured', 'score': 61849, 'tags': ['adj', 'v']}, {'word': 'related', 'score': 61564, 'tags': ['adj', 'v']}]\n",
    "        sel_compared = dm_compared[random.randint(0, len(dm_compared)-1)]\n",
    "        \n",
    "        if(percent_change != 0):\n",
    "            steps.append(\n",
    "                f\"{x_is_up_str} by {percent_change} when {sel_compared['word']} to {entity2}'s {value_title}.\")\n",
    "        return steps\n",
    "    \n",
    "    #####\n",
    "    def add_horzBar_chart(self, data_dict, title, period, prev_data_dict=None, diff_prev_entity=False):\n",
    "        steps = []\n",
    "        #steps = []\n",
    "        avg_num = float(data_dict.curr_period_avg)\n",
    "        \n",
    "        #dm_organization = [{'word':'organization'}, {'word':'company'}]\n",
    "        #dm_organization.extend(api.words(ml='organization', max=10))\n",
    "        dm_organization = [{'word': 'organization'}, {'word': 'company'}, {'word': 'establishment', 'score': 80499, 'tags': ['syn', 'n']}, {'word': 'governance', 'score': 79453, 'tags': ['syn', 'n']}, {'word': 'system', 'score': 78919, 'tags': ['syn', 'n']}, {'word': 'formation', 'score': 77741, 'tags': ['syn', 'n']}, {'word': 'organisation', 'score': 76951, 'tags': ['syn', 'n']}, {'word': 'constitution', 'score': 76578, 'tags': ['syn', 'n']}, {'word': 'administration', 'score': 76073, 'tags': ['syn', 'n']}, {'word': 'arrangement', 'score': 75303, 'tags': ['syn', 'n']}, {'word': 'brass', 'score': 74898, 'tags': ['syn', 'n']}, {'word': 'group', 'score': 69572, 'tags': ['n']}]\n",
    "        sel_organization = dm_organization[random.randint(0, len(dm_organization)-1)]\n",
    "        #print(sel_organization)\n",
    "\n",
    "        #dm_headquartered = [{'word':'headquartered'}]\n",
    "        #dm_headquartered.extend(api.words(ml='headquartered', max=10))\n",
    "        dm_headquartered=[{'word': 'headquartered'}, {'word': 'based', 'score': 70081, 'tags': ['adj', 'v']}, {'word': 'located', 'score': 69250, 'tags': ['adj', 'v']}, {'word': 'situated', 'score': 62356, 'tags': ['adj', 'v']}, {'word': 'established', 'score': 60773, 'tags': ['adj', 'v']}, {'word': 'stationed', 'score': 60609, 'tags': ['v']}, {'word': 'housed', 'score': 60320, 'tags': ['v']}, {'word': 'prepared', 'score': 53106, 'tags': ['adj']}, {'word': 'seat', 'score': 52692, 'tags': ['n']}, {'word': 'employs', 'score': 51143, 'tags': ['v']}, {'word': 'operates', 'score': 51142, 'tags': ['v']}]\n",
    "        sel_headquartered = dm_headquartered[random.randint(0, len(dm_headquartered)-1)]\n",
    "        \n",
    "        steps.append(\n",
    "            f\"{data_dict.company} is a(n) {data_dict.domain} {sel_organization['word']} {sel_headquartered['word']} at {data_dict.hq}\")\n",
    "        \n",
    "        dm_stockmarket = ['stock market', 'stock exchange']\n",
    "        sel_stockmarket = dm_stockmarket[random.randint(0, len(dm_stockmarket)-1)]\n",
    "        \n",
    "        #dm_timeperiod = [{'word':'time period'}]\n",
    "        #dm_timeperiod.extend(api.words(ml='time period', max=5))\n",
    "        dm_timeperiod=[{'word': 'time period'}, {'word': 'period', 'score': 64621, 'tags': ['syn', 'n']}, {'word': 'period of time', 'score': 63576, 'tags': ['syn', 'n']}, {'word': 'era', 'score': 62529, 'tags': ['syn', 'n']}, {'word': 'day', 'score': 57329, 'tags': ['syn', 'n']}, {'word': 'eon', 'score': 57329, 'tags': ['syn', 'n']}]\n",
    "        sel_timeperiod = dm_timeperiod[random.randint(0, len(dm_timeperiod)-1)]\n",
    "        \n",
    "        steps.append(\n",
    "            f\"{Human().get_lets_look_at()} the {data_dict.company}'s {sel_stockmarket} in the {sel_timeperiod['word']} from {data_dict.start_ts} to {data_dict.end_ts}\")\n",
    "        #steps.append(f\"{Human().get_lets_see()}\")\n",
    "        \n",
    "        #dm_highest = [{'word':'most'}, {'word':'highest'}, {'word':'greatest'}]\n",
    "        #dm_highest.extend(api.words(ml='highest', max=15))\n",
    "        dm_highest=[{'word': 'most'}, {'word': 'highest'}, {'word': 'greatest'}, {'word': 'maximum', 'score': 82033, 'tags': ['syn', 'adj']}, {'word': 'peak', 'score': 81553, 'tags': ['syn', 'adj', 'n']}, {'word': 'ultimate', 'score': 78440, 'tags': ['syn', 'adj']}, {'word': 'maximal', 'score': 76201, 'tags': ['syn', 'adj']}, {'word': 'strongest', 'score': 68244, 'tags': ['adj']}, {'word': 'loftiest', 'score': 67701, 'tags': ['adj']}, {'word': 'top', 'score': 67296, 'tags': ['adj']}, {'word': 'greatest', 'score': 67213, 'tags': ['adj']}, {'word': 'best', 'score': 66218, 'tags': ['adj', 'n']}, {'word': 'largest', 'score': 65954, 'tags': ['adj']}, {'word': 'widest', 'score': 65694, 'tags': ['adj']}, {'word': 'worst', 'score': 65648, 'tags': ['adj']}, {'word': 'topmost', 'score': 65563, 'tags': ['adj']}, {'word': 'biggest', 'score': 65459, 'tags': ['adj']}, {'word': 'fastest', 'score': 64957, 'tags': ['adv', 'adj']}]\n",
    "        sel_highest = dm_highest[random.randint(0, len(dm_highest)-1)]\n",
    "        \n",
    "        #dm_lowest = [{'word':'lowest'}]\n",
    "        #dm_lowest.extend(api.words(ml='lowest', max=15))\n",
    "        dm_lowest=[{'word': 'lowest'}, {'word': 'worst', 'score': 88319, 'tags': ['syn', 'adj']}, {'word': 'smallest', 'score': 87730, 'tags': ['syn', 'adj']}, {'word': 'minimum', 'score': 81602, 'tags': ['syn', 'adj', 'n']}, {'word': 'last', 'score': 81060, 'tags': ['syn', 'adj']}, {'word': 'least', 'score': 79667, 'tags': ['syn', 'adj']}, {'word': 'bottom', 'score': 78608, 'tags': ['syn', 'adj']}, {'word': 'minimal', 'score': 77839, 'tags': ['syn', 'adj']}, {'word': 'last-place', 'score': 71197, 'tags': ['syn', 'adj']}, {'word': 'weakest', 'score': 71196, 'tags': ['adj']}, {'word': 'fewest', 'score': 70085, 'tags': ['adj']}, {'word': 'slowest', 'score': 66344, 'tags': ['adv', 'adj']}, {'word': 'cheapest', 'score': 66234, 'tags': ['adj']}, {'word': 'shortest', 'score': 65088, 'tags': ['adj']}, {'word': 'below', 'score': 64758, 'tags': ['adv']}, {'word': 'best', 'score': 64732, 'tags': ['adj']}]\n",
    "        sel_lowest = dm_lowest[random.randint(0, len(dm_lowest)-1)]\n",
    "        \n",
    "        dm_price = ['price', 'value', 'cost', 'quote']\n",
    "        sel_price = dm_price[random.randint(0, len(dm_price)-1)]\n",
    "        \n",
    "        #dm_approximately = [{'word':'approximately'}]\n",
    "        #dm_approximately.extend(api.words(ml='approximately', max=15))\n",
    "        dm_approximately=[{'word': 'approximately'}, {'word': 'roughly', 'score': 94205, 'tags': ['syn', 'adv']}, {'word': 'around', 'score': 82887, 'tags': ['syn', 'adv']}, {'word': 'about', 'score': 80101, 'tags': ['syn', 'adv']}, {'word': 'more or less', 'score': 78759, 'tags': ['syn', 'adv']}, {'word': 'some', 'score': 78120, 'tags': ['syn', 'adv']}, {'word': 'close to', 'score': 75489, 'tags': ['syn', 'adv']}, {'word': 'just about', 'score': 73011, 'tags': ['syn', 'adv']}, {'word': 'or so', 'score': 72686, 'tags': ['syn', 'adv']}, {'word': 'approx', 'score': 72213, 'tags': ['n']}, {'word': 'estimated', 'score': 69496, 'tags': ['adj', 'v']}, {'word': 'nearly', 'score': 66875, 'tags': ['adv']}, {'word': 'average', 'score': 64748, 'tags': ['adj', 'n', 'adv', 'v']}, {'word': 'substantially', 'score': 61718, 'tags': ['adv']}, {'word': 'significantly', 'score': 60474, 'tags': ['adv']}, {'word': 'almost', 'score': 60151, 'tags': ['adv']}]\n",
    "        sel_approximately = dm_approximately[random.randint(0, len(dm_approximately)-1)]\n",
    "            \n",
    "        #dm_compared = [{'word':'compared'}]\n",
    "        #dm_compared.extend(api.words(ml='compared', max=10))\n",
    "        dm_compared=[{'word': 'compared'}, {'word': 'versus', 'score': 70844, 'tags': ['n', 'v']}, {'word': 'comparison', 'score': 70308, 'tags': ['n']}, {'word': 'contrasted', 'score': 68805, 'tags': ['v']}, {'word': 'equated', 'score': 66307, 'tags': ['v']}, {'word': 'comparative', 'score': 64868, 'tags': ['adj', 'n']}, {'word': 'matched', 'score': 62311, 'tags': ['adj', 'v']}, {'word': 'relative', 'score': 62259, 'tags': ['adj']}, {'word': 'comparisons', 'score': 61965, 'tags': ['n']}, {'word': 'measured', 'score': 61849, 'tags': ['adj', 'v']}, {'word': 'related', 'score': 61564, 'tags': ['adj', 'v']}]\n",
    "        sel_compared = dm_compared[random.randint(0, len(dm_compared)-1)]\n",
    "\n",
    "        steps.append(\n",
    "            f\"{data_dict.company} had the {sel_highest['word']} stock {sel_price} with ${data_dict.curr_period_max}\")\n",
    "        steps.append(\n",
    "            f\"{data_dict.company} had the {sel_lowest['word']} stock price with ${data_dict.curr_period_min}\")\n",
    "        steps.append(f\"And the average this {sel_timeperiod['word']} is {sel_approximately['word']} ${data_dict.curr_period_avg}, give or take {data_dict.curr_period_var}\")\n",
    "        \n",
    "        today = datetime.datetime.now()\n",
    "        relperiod = self.reltime(today, today)\n",
    "        #print(relperiod)\n",
    "        period = \"week\"\n",
    "        if prev_data_dict != None:\n",
    "            if data_dict.symbol == prev_data_dict.symbol:\n",
    "                diff_prev_entity = False\n",
    "                date1 = datetime.datetime.strptime(prev_data_dict.start_ts, '%d_%b_%Y')\n",
    "                date2 = datetime.datetime.strptime(data_dict.start_ts, '%d_%b_%Y')\n",
    "                if date1 > date2:\n",
    "                    temp = date2\n",
    "                    date2 = date1\n",
    "                    date1 = temp\n",
    "                relperiod = self.reltime(date1, date2)\n",
    "                print(relperiod)\n",
    "                if \"day\" in relperiod:\n",
    "                    period = \"day\"\n",
    "                elif \"week\" in relperiod:\n",
    "                    period = 'week'\n",
    "                elif \"month\" in relperiod:\n",
    "                    period = \"month\"\n",
    "                elif \"year\" in relperiod:\n",
    "                    period = \"year\"\n",
    "            else:\n",
    "                diff_prev_entity = True\n",
    "        \n",
    "\n",
    "        #dm_increase = [{'word':'increase'}]\n",
    "        #dm_increase.extend(api.words(ml='increase', max=15))\n",
    "        dm_increase=[{'word': 'increase'}, {'word': 'growth', 'score': 120808, 'tags': ['syn', 'n']}, {'word': 'gain', 'score': 119119, 'tags': ['syn', 'v', 'n']}, {'word': 'increment', 'score': 118913, 'tags': ['syn', 'n']}, {'word': 'addition', 'score': 112300, 'tags': ['syn', 'n']}, {'word': 'step-up', 'score': 105114, 'tags': ['syn', 'n']}, {'word': 'decrease', 'score': 105113, 'tags': ['n', 'v', 'ant']}, {'word': 'rise', 'score': 98407, 'tags': ['n', 'v']}, {'word': 'decline', 'score': 97684, 'tags': ['n', 'v']}, {'word': 'spike', 'score': 96069, 'tags': ['n']}, {'word': 'upsurge', 'score': 95837, 'tags': ['n']}, {'word': 'doubling', 'score': 95187, 'tags': ['n']}, {'word': 'higher', 'score': 94979, 'tags': ['adj']}, {'word': 'improvement', 'score': 94451, 'tags': ['n']}, {'word': 'boost', 'score': 94202, 'tags': ['n', 'v']}, {'word': 'escalation', 'score': 93683, 'tags': ['n']}]\n",
    "        sel_increase = dm_increase[random.randint(0, len(dm_increase)-1)]\n",
    "        \n",
    "        #dm_decrease = [{'word':'decrease'}]\n",
    "        #dm_decrease.extend(api.words(ml='decrease', max=15))\n",
    "        dm_decrease=[{'word': 'decrease'}, {'word': 'reduction', 'score': 128795, 'tags': ['syn', 'n']}, {'word': 'diminution', 'score': 121587, 'tags': ['syn', 'n']}, {'word': 'lessening', 'score': 120654, 'tags': ['syn', 'n']}, {'word': 'lessen', 'score': 118908, 'tags': ['syn', 'v', 'n']}, {'word': 'diminish', 'score': 117613, 'tags': ['syn', 'v']}, {'word': 'decrement', 'score': 116952, 'tags': ['syn', 'n']}, {'word': 'fall', 'score': 115989, 'tags': ['syn', 'v', 'n']}, {'word': 'drop-off', 'score': 105118, 'tags': ['syn', 'n']}, {'word': 'step-down', 'score': 105118, 'tags': ['syn', 'n']}, {'word': 'increase', 'score': 105117, 'tags': ['n', 'v', 'adj', 'ant']}, {'word': 'decline', 'score': 100253, 'tags': ['n', 'v']}, {'word': 'reductions', 'score': 96896, 'tags': ['n']}, {'word': 'reduce', 'score': 96065, 'tags': ['v', 'n']}]\n",
    "        sel_decrease = dm_decrease[random.randint(0, len(dm_decrease)-1)]\n",
    "        \n",
    "        dm_last = ['last', 'past', 'previous', 'latest', 'latter']\n",
    "        sel_last = dm_last[random.randint(0, len(dm_last)-1)]\n",
    "        \n",
    "        #dm_next = [{'word':'next'}]\n",
    "        #dm_next.extend(api.words(ml='next', max=15))\n",
    "        dm_next=[{'word': 'next'}, {'word': 'future', 'score': 82102, 'tags': ['syn', 'adj']}, {'word': 'following', 'score': 78347, 'tags': ['syn', 'adj', 'v']}, {'word': 'close', 'score': 74475, 'tags': ['syn', 'adj']}, {'word': 'succeeding', 'score': 74381, 'tags': ['syn', 'v']}, {'word': 'incoming', 'score': 74045, 'tags': ['syn', 'adj']}, {'word': 'adjacent', 'score': 70880, 'tags': ['syn', 'adj']}, {'word': 'side by side', 'score': 68622, 'tags': ['syn', 'adj']}, {'word': 'last', 'score': 68621, 'tags': ['adj']}, {'word': 'later', 'score': 67766, 'tags': ['adv']}, {'word': 'first', 'score': 66709, 'tags': ['adj', 'n']}, {'word': 'upcoming', 'score': 66681, 'tags': ['adj']}, {'word': 'coming', 'score': 66523, 'tags': ['n', 'v']}, {'word': 'ahead', 'score': 65899, 'tags': ['adv']}, {'word': 'expected', 'score': 64567, 'tags': ['adj']}, {'word': 'second', 'score': 64101, 'tags': ['adj', 'n']}]\n",
    "        sel_next = dm_next[random.randint(0, len(dm_next)-1)]\n",
    "        \n",
    "        #dm_expected = [{'word':'expected'}, {'word':'projected'}]\n",
    "        #dm_expected.extend(api.words(ml='expected', max=15))\n",
    "        dm_expected=[{'word': 'expected'}, {'word': 'projected'}, {'word': 'likely', 'score': 102293, 'tags': ['syn', 'adj']}, {'word': 'anticipated', 'score': 101205, 'tags': ['syn', 'adj', 'v']}, {'word': 'predicted', 'score': 99744, 'tags': ['syn', 'adj', 'v']}, {'word': 'supposed', 'score': 94975, 'tags': ['syn', 'adj', 'v']}, {'word': 'due', 'score': 94220, 'tags': ['syn', 'adj']}, {'word': 'awaited', 'score': 92717, 'tags': ['syn', 'v']}, {'word': 'foreseen', 'score': 90287, 'tags': ['syn', 'adj']}, {'word': 'potential', 'score': 86611, 'tags': ['syn', 'adj', 'n']}, {'word': 'foretold', 'score': 86041, 'tags': ['syn', 'adj']}, {'word': 'unsurprising', 'score': 86016, 'tags': ['syn', 'adj']}, {'word': 'prospective', 'score': 84239, 'tags': ['syn', 'adj']}, {'word': 'hoped-for', 'score': 79977, 'tags': ['syn', 'adj']}, {'word': 'matter-of-course', 'score': 79977, 'tags': ['syn', 'adj']}, {'word': 'slated', 'score': 78513, 'tags': ['v']}, {'word': 'scheduled', 'score': 77463, 'tags': ['adj', 'v']}]\n",
    "        sel_expected = dm_expected[random.randint(0, len(dm_expected)-1)]\n",
    "        \n",
    "        #dm_trend = [{'word':'trend'}]\n",
    "        #dm_trend.extend(api.words(ml='trend', max=15))\n",
    "        dm_trend=[{'word': 'trend'}, {'word': 'vogue', 'score': 86524, 'tags': ['syn', 'n']}, {'word': 'tendency', 'score': 85031, 'tags': ['syn', 'n']}, {'word': 'drift', 'score': 84072, 'tags': ['syn', 'n']}, {'word': 'curve', 'score': 83434, 'tags': ['syn', 'n']}, {'word': 'style', 'score': 80197, 'tags': ['syn', 'n']}, {'word': 'slew', 'score': 79128, 'tags': ['syn', 'n']}, {'word': 'veer', 'score': 79058, 'tags': ['syn', 'v']}, {'word': 'course', 'score': 78914, 'tags': ['syn', 'n']}, {'word': 'slue', 'score': 78455, 'tags': ['syn', 'v']}, {'word': 'swerve', 'score': 77678, 'tags': ['syn', 'n']}, {'word': 'cut', 'score': 75482, 'tags': ['syn', 'n']}, {'word': 'sheer', 'score': 74189, 'tags': ['syn', 'adj']}, {'word': 'pattern', 'score': 70179, 'tags': ['n']}, {'word': 'downtrend', 'score': 69353, 'tags': ['n']}, {'word': 'phenomenon', 'score': 68249, 'tags': ['n']}]\n",
    "        sel_trend = dm_trend[random.randint(0, len(dm_trend)-1)]\n",
    "        \n",
    "        #dm_understand = [{'word':'understand'}, {'word':'make sense out of'}, {'word':'read'}]\n",
    "        #dm_understand.extend(api.words(ml='understand', max=15))\n",
    "        dm_understand=[{'word': 'understand'}, {'word': 'make sense out of'}, {'word': 'read'}, {'word': 'realize', 'score': 98620, 'tags': ['syn', 'v']}, {'word': 'empathize', 'score': 94176, 'tags': ['syn', 'v']}, {'word': 'sympathize', 'score': 93347, 'tags': ['syn', 'v']}, {'word': 'interpret', 'score': 93237, 'tags': ['syn', 'v']}, {'word': 'infer', 'score': 91127, 'tags': ['syn', 'v']}, {'word': 'see', 'score': 90852, 'tags': ['syn', 'v']}, {'word': 'read', 'score': 88372, 'tags': ['syn', 'v']}, {'word': 'translate', 'score': 86458, 'tags': ['syn', 'v']}, {'word': 'gather', 'score': 84482, 'tags': ['syn', 'v']}, {'word': 'comprehend', 'score': 75670, 'tags': ['v']}, {'word': 'know', 'score': 74661, 'tags': ['v', 'n']}, {'word': 'explain', 'score': 74490, 'tags': ['v']}, {'word': 'recognize', 'score': 71816, 'tags': ['v']}, {'word': 'appreciate', 'score': 71293, 'tags': ['v']}, {'word': 'learn', 'score': 70076, 'tags': ['v']}]\n",
    "        sel_understand = dm_understand[random.randint(0, len(dm_understand)-1)]\n",
    "        \n",
    "        \n",
    "        if prev_data_dict != None and not diff_prev_entity:\n",
    "            #steps.append(\n",
    "            #    f\"{Human().get_fill()} the {title} with past {data_dict.period}\")\n",
    "            #past_avg_num = prev_data_dict.get_average()\n",
    "            past_avg_value = prev_data_dict.curr_period_avg\n",
    "            past_avg_num = float(prev_data_dict.curr_period_avg)\n",
    "            past_var_value = prev_data_dict.curr_period_var\n",
    "            steps.append(f\"{relperiod}, the average stock {sel_price} for {data_dict.company} was ${past_avg_value}, give or take {past_var_value}\")\n",
    "            if (avg_num > past_avg_num):\n",
    "                diff = data_dict.data_to_text_conversion_str(avg_num - past_avg_num)\n",
    "                projection = data_dict.data_to_text_conversion_str(avg_num + (avg_num - past_avg_num))\n",
    "                steps.append(f\"That is an average {sel_increase['word']} of ${diff} {sel_compared['word']} to {sel_last} {period}! {Human().get_positive()}\")\n",
    "                steps.append(f\"The {sel_expected['word']} average stock {sel_price} for {data_dict.company} in the {sel_next['word']} {period} is {projection}!\")\n",
    "            if (avg_num < past_avg_num):\n",
    "                diff = data_dict.data_to_text_conversion_str(past_avg_num - avg_num)\n",
    "                projection = data_dict.data_to_text_conversion_str(avg_num - (past_avg_num - avg_num))\n",
    "                steps.append(f\"That is an average {sel_decrease['word']} of ${diff} {sel_compared['word']} to {sel_last} {period}! {Human().get_negative()}\")\n",
    "                steps.append(f\"The {sel_expected['word']} average stock {sel_price} for {data_dict.company} in the {sel_next['word']} {period} is {projection}!\")\n",
    "            if (avg_num == past_avg_num):\n",
    "                steps.append(f\"The stock {sel_price} average is keeping up at {past_avg_value} {sel_compared['word']} to {sel_last} {period}! {Human().get_neutral()}\")\n",
    "            metrics_title = f\"{Human().get_more()}. Here is some Averages {sel_trend['word']} to {sel_understand['word']}!\"\n",
    "            metrics_subject = f\"{data_dict.company} Averages\"\n",
    "            metrics = self.add_metric_chart(avg_num, past_avg_num, metrics_title, metrics_subject)\n",
    "            for step in metrics:\n",
    "                steps.append(step)\n",
    "                                                                                          \n",
    "        #dm_sector = [{'word':'sector'}]\n",
    "        #dm_sector.extend(api.words(ml='sector', max=15))\n",
    "        dm_sector=[{'word': 'sector'}, {'word': 'sphere', 'score': 90711, 'tags': ['syn', 'n']}, {'word': 'industries', 'score': 72882, 'tags': ['n']}, {'word': 'industry', 'score': 71815, 'tags': ['n']}, {'word': 'economy', 'score': 69727, 'tags': ['n']}, {'word': 'companies', 'score': 69230, 'tags': ['n']}, {'word': 'market', 'score': 68603, 'tags': ['n']}, {'word': 'sectoral', 'score': 68418, 'tags': ['adj']}, {'word': 'sectorial', 'score': 66538, 'tags': ['adj']}, {'word': 'government', 'score': 65086, 'tags': ['n']}, {'word': 'enterprises', 'score': 64985, 'tags': ['n']}, {'word': 'industrial', 'score': 64793, 'tags': ['adj', 'n']}, {'word': 'institutions', 'score': 64647, 'tags': ['n']}, {'word': 'agriculture', 'score': 64546, 'tags': ['n']}, {'word': 'manufacturing', 'score': 63992, 'tags': ['n', 'v']}, {'word': 'businesses', 'score': 63792, 'tags': ['n']}]\n",
    "        sel_sector = dm_sector[random.randint(0, len(dm_sector)-1)]        \n",
    "        if prev_data_dict != None and diff_prev_entity:\n",
    "            #steps.append(\n",
    "            #    f\"{Human().get_fill()} the {title} of {data_dict.business_units} with {prev_data_dict.business_units}\")\n",
    "            steps.append(\n",
    "                f\"{prev_data_dict.company} is a(n) {sel_organization['word']} in {prev_data_dict.domain} {sel_sector['word']} {sel_headquartered['word']} at {prev_data_dict.hq}\")\n",
    "            past_avg_value = prev_data_dict.curr_period_avg\n",
    "            past_avg_num = float(prev_data_dict.curr_period_avg)\n",
    "            past_var_value = prev_data_dict.curr_period_var\n",
    "            steps.append(f\"{prev_data_dict.company} averages at ${past_avg_value}, give or take {past_var_value}\")\n",
    "            if (avg_num > past_avg_num):\n",
    "                diff = data_dict.data_to_text_conversion_str(avg_num - past_avg_num)\n",
    "                projection = data_dict.data_to_text_conversion_str(avg_num + (avg_num - past_avg_num))\n",
    "                steps.append(f\"That is an average {sel_increase['word']} of {diff} for {prev_data_dict.company} {sel_compared['word']} to {data_dict.company} stock {sel_price}! {Human().get_positive()}\")\n",
    "                #steps.append(f\"The projected average {data_dict.measure} next {data_dict.period} is {projection}!\")\n",
    "            if (avg_num < past_avg_num):\n",
    "                diff = data_dict.data_to_text_conversion_str(past_avg_num - avg_num)\n",
    "                projection = data_dict.data_to_text_conversion_str(avg_num - (past_avg_num - avg_num))\n",
    "                steps.append(f\"That is an average {sel_decrease['word']} of {diff} for {prev_data_dict.company} {sel_compared['word']} to {data_dict.company} stock {sel_price}! {Human().get_negative()}\")\n",
    "                #steps.append(f\"The projected average {data_dict.measure} next {data_dict.period} is {projection}!\")\n",
    "            if (avg_num == past_avg_num):\n",
    "                steps.append(f\"{sel_stockmarket} averages for both {data_dict.company} and {prev_data_dict.company} has been trending at {past_avg_value} for the {sel_last} few {period}s! {Human().get_neutral()}\")\n",
    "            metrics_title = f\"{Human().get_more()}\"\n",
    "            metrics = self.add_line_chart(data_dict.company, prev_data_dict.company, metrics_title, \"Averages\", avg_num, past_avg_num)\n",
    "            for step in metrics:\n",
    "                steps.append(step)\n",
    "                \n",
    "        return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "def listToString(s):  \n",
    "    \n",
    "    # initialize an empty string \n",
    "    str1 = \"\"  \n",
    "    \n",
    "    s1 = sample(s, 4) #len(s)\n",
    "    # traverse in the string   \n",
    "    for ele in s1:  \n",
    "        str1 += ele + '.'\n",
    "    \n",
    "    # return string   \n",
    "    return str1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['MSFT', '60.52', '59.87', '61', '0.27', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '28_Oct_2016']\n['MSFT', '57.67', '57.44', '58.12', '0.07', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '19_Aug_2016']\n['MSFT', '57.94', '57.67', '58.17', '0.03', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '26_Aug_2016']\n['AAPL', '109.71', '107.79', '111.06', '2.25', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '11_Nov_2016']\n['MSFT', '59.76', '58.7', '60.47', '0.69', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '11_Nov_2016']\n['AAPL', '108.56', '105.71', '110.06', '4.11', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '18_Nov_2016']\n['MSFT', '62.54', '62.17', '62.98', '0.1', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '16_Dec_2016']\n['MSFT', '62.83', '62.14', '63.28', '0.24', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '30_Dec_2016']\n['MSFT', '59.41', '58.71', '59.92', '0.24', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '04_Nov_2016']\n['MSFT', '60.9', '59.95', '61.97', '0.69', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '09_Dec_2016']\n['MSFT', '59.53', '58.12', '60.64', '1.09', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '18_Nov_2016']\n['MSFT', '57.58', '56.9', '58.03', '0.21', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '30_Sep_2016']\n['MSFT', '57.86', '57.22', '59.66', '1.04', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '21_Oct_2016']\n['AAPL', '111.64', '111.23', '111.8', '0.07', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '25_Nov_2016']\n['MSFT', '57.23', '56.21', '57.66', '0.47', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '09_Sep_2016']\n['AAPL', '115.94', '113.72', '118.25', '3.86', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '28_Oct_2016']\n['AAPL', '113.3', '112.52', '114.06', '0.42', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '07_Oct_2016']\n['MSFT', '60.73', '60.4', '61.12', '0.11', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '25_Nov_2016']\n['AAPL', '109.3', '109.08', '109.48', '0.02', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '19_Aug_2016']\n['AAPL', '113.03', '112.18', '113.95', '0.4', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '30_Sep_2016']\n['AAPL', '115.09', '113.3', '115.97', '1.13', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '16_Dec_2016']\n['MSFT', '57.74', '57.46', '58.1', '0.06', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '02_Sep_2016']\n['AAPL', '113.61', '112.71', '114.62', '0.46', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '23_Sep_2016']\n['MSFT', '57.35', '56.81', '57.82', '0.22', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '23_Sep_2016']\n['MSFT', '57.57', '57.24', '57.8', '0.05', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '07_Oct_2016']\n['MSFT', '57.34', '56.92', '58.04', '0.19', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '14_Oct_2016']\n['MSFT', '63.5', '63.24', '63.62', '0.02', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '23_Dec_2016']\n['AAPL', '107.98', '106.94', '108.85', '0.57', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '26_Aug_2016']\n['AAPL', '106.18', '103.13', '108.36', '5.6', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '09_Sep_2016']\n['AAPL', '111.06', '108.84', '113.54', '3.26', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '04_Nov_2016']\n['MSFT', '56.86', '56.26', '57.25', '0.19', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '16_Sep_2016']\n['AAPL', '117.16', '116.6', '117.55', '0.14', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '21_Oct_2016']\n['AAPL', '110.59', '109.49', '111.57', '0.85', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '02_Dec_2016']\n['AAPL', '111.23', '109.11', '113.95', '3.59', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '09_Dec_2016']\n['AAPL', '106.68', '106', '107.73', '0.48', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '02_Sep_2016']\n['AAPL', '116.64', '115.82', '117.26', '0.36', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '30_Dec_2016']\n['AAPL', '116.69', '116.29', '117.06', '0.1', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '23_Dec_2016']\n['MSFT', '60.08', '59.2', '61.09', '0.7', 'Microsoft', 'Information_Technology', 'Systems_Software', 'Redmond,Washington', '02_Dec_2016']\n['AAPL', '116.86', '116.05', '117.63', '0.45', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '14_Oct_2016']\n['AAPL', '111.13', '105.44', '115.57', '19.24', 'Apple', 'Information_Technology', 'Computer_Hardware', 'Cupertino,California', '16_Sep_2016']\n"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "f = open(\"summary.txt\", \"a\")\n",
    "f1 = open(\"input.txt\", \"a\")\n",
    "\n",
    "with open('export.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        for i, _ in enumerate(row):\n",
    "            row[i] = row[i].replace(\", \", \",\")\n",
    "            row[i] = row[i].replace(' ', '_')\n",
    "        mydict_obj = StockDataDict(\n",
    "        symbol=row[0],\n",
    "        last_week_close_price='0',\n",
    "        start_ts = datetime.datetime.strptime(row[9],\"%d_%b_%Y\"),\n",
    "        end_ts= (datetime.datetime.strptime(row[9],\"%d_%b_%Y\") + datetime.timedelta(days = (7))).strftime(\"%d_%b_%Y\"),\n",
    "        curr_period_avg=row[1],\n",
    "        curr_period_min=row[2],\n",
    "        curr_period_max=row[3],\n",
    "        curr_period_var=row[4],\n",
    "        numeric_units=DataType.dollar,\n",
    "        company=row[5],\n",
    "        hq=row[8],\n",
    "        domain=row[6] + '(' + row[7] + ')'\n",
    "        )\n",
    "        summary = (Narrator('week').add_horzBar_chart(mydict_obj, \"\", '1 Week'))\n",
    "        f.write(listToString(summary) + '\\n')\n",
    "        input_line = \"symbol_1:\"+row[0] + \" \tstartts_1:\" + row[9] + \" \tendts_1:\" + (datetime.datetime.strptime(row[9] , \"%d_%b_%Y\")  +  datetime.timedelta(days = (7))).strftime(\"%d_%b_%Y\") + \" \tcurrperiodavg_1:\"+row[1] + \" \tcurrperiodmin_1:\" + row[2] + \" \tcurrperiodmax_1:\" + row[3] + \" \tcurrperiodvar_1:\" + row[4] + \" \tnumericunits_1:$\" + \" \tcompany_1:\" + row[5] + \" \thq_1:\" + row[8] + \" \tdomain_1:\" + row[6]  + \" \tdomain_2:\" +  '('  +  \" \tdomain_3:\" + row[7]  + \" \tdomain_4:\" + ')'\n",
    "        f1.write(input_line + '\\n')\n",
    "        print(row)\n",
    "        \n",
    "f.close()\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "today\n2 months ago\n2 months ago\nlast month\n2 months ago\n2 months ago\nlast Friday 7 days ago\n2 months ago\nlast month\nlast month\nlast Friday 7 days ago\nlast month\nlast month\nlast month\nlast month\n21 days ago\n14 days ago\n2 months ago\nlast month\n2 months ago\n2 months ago\ntoday\nlast Friday 7 days ago\n3 months ago\n4 months ago\n4 months ago\n3 months ago\n4 months ago\n3 months ago\nlast month\n2 months ago\nlast month\n3 months ago\nlast month\nlast month\n2 months ago\n2 months ago\n4 months ago\nlast month\n4 months ago\n2 months ago\nlast Friday 7 days ago\ntoday\n3 months ago\n4 months ago\n4 months ago\n3 months ago\n4 months ago\n3 months ago\nlast month\n2 months ago\nlast month\n3 months ago\nlast Friday 7 days ago\nlast month\n2 months ago\n2 months ago\n4 months ago\nlast month\n4 months ago\ntoday\nlast Friday 7 days ago\n14 days ago\nlast month\nlast month\n3 months ago\n2 months ago\nlast month\n2 months ago\n3 months ago\n2 months ago\nlast Friday 7 days ago\nlast month\nlast month\nlast month\n2 months ago\nlast month\nlast month\nlast month\n2 months ago\nlast month\n3 months ago\n3 months ago\ntoday\nlast month\nlast month\nlast Friday 7 days ago\nlast month\nlast Friday 7 days ago\n2 months ago\nlast month\n2 months ago\n14 days ago\n2 months ago\n2 months ago\nlast month\nlast month\nlast month\n2 months ago\nlast month\nlast Friday 7 days ago\ntoday\nlast Friday 7 days ago\nlast month\nlast month\n3 months ago\n2 months ago\nlast month\n2 months ago\n3 months ago\n2 months ago\n14 days ago\nlast month\nlast month\nlast month\n2 months ago\nlast month\nlast month\nlast month\n2 months ago\n2 months ago\n4 months ago\n4 months ago\nlast month\ntoday\n14 days ago\nlast month\nlast Friday 7 days ago\nlast month\n3 months ago\n2 months ago\n3 months ago\nlast month\n3 months ago\n3 months ago\n2 months ago\n2 months ago\nlast Friday 7 days ago\n3 months ago\n14 days ago\n2 months ago\n4 months ago\n4 months ago\nlast month\n14 days ago\ntoday\nlast month\n21 days ago\nlast month\n3 months ago\n2 months ago\n3 months ago\nlast month\n3 months ago\n3 months ago\n2 months ago\n2 months ago\nlast Friday 7 days ago\n3 months ago\n28 days ago\nlast Friday 7 days ago\n3 months ago\n3 months ago\nlast Friday 7 days ago\nlast month\nlast month\ntoday\nlast month\n14 days ago\n2 months ago\nlast month\n2 months ago\n21 days ago\n2 months ago\n2 months ago\nlast month\nlast month\nlast month\n2 months ago\nlast month\n2 months ago\n4 months ago\n4 months ago\nlast month\nlast Friday 7 days ago\n21 days ago\nlast month\ntoday\nlast month\n3 months ago\n2 months ago\n3 months ago\nlast month\n3 months ago\n3 months ago\n2 months ago\n2 months ago\n14 days ago\n3 months ago\nlast Friday 7 days ago\nlast month\n3 months ago\n3 months ago\nlast Friday 7 days ago\nlast month\nlast month\n14 days ago\nlast month\ntoday\n2 months ago\nlast month\n2 months ago\nlast Friday 7 days ago\n2 months ago\n2 months ago\nlast month\nlast month\nlast month\n2 months ago\nlast month\nlast month\nlast month\nlast month\n2 months ago\n3 months ago\n3 months ago\n2 months ago\n3 months ago\n2 months ago\ntoday\nlast month\n21 days ago\n2 months ago\n28 days ago\nlast Friday 7 days ago\nlast Friday 7 days ago\nlast month\n3 months ago\n14 days ago\n3 months ago\nlast Friday 7 days ago\n2 months ago\n2 months ago\nlast month\n2 months ago\n2 months ago\nlast month\n2 months ago\nlast month\nlast month\ntoday\nlast month\nlast month\nlast month\nlast month\n14 days ago\nlast Friday 7 days ago\n2 months ago\nlast month\n2 months ago\n14 days ago\nlast Friday 7 days ago\ntoday\nlast month\nlast month\n3 months ago\n2 months ago\nlast month\n2 months ago\n3 months ago\n2 months ago\n21 days ago\nlast month\nlast Friday 7 days ago\nlast month\n2 months ago\nlast month\nlast month\nlast month\n2 months ago\nlast month\nlast month\nlast month\n2 months ago\n3 months ago\n3 months ago\n2 months ago\n3 months ago\n2 months ago\n21 days ago\nlast month\ntoday\n2 months ago\nlast Friday 7 days ago\n14 days ago\nlast month\nlast month\n3 months ago\nlast Friday 7 days ago\n3 months ago\nlast month\nlast month\nlast month\ntoday\n21 days ago\n2 months ago\nlast month\n2 months ago\nlast month\n2 months ago\nlast month\nlast Friday 7 days ago\nlast Friday 7 days ago\n2 months ago\n2 months ago\nlast month\n2 months ago\n2 months ago\n14 days ago\nlast month\nlast month\nlast month\nlast month\n21 days ago\ntoday\n2 months ago\nlast Friday 7 days ago\n2 months ago\nlast month\n2 months ago\nlast month\nlast month\n14 days ago\n2 months ago\n2 months ago\nlast month\n2 months ago\n2 months ago\nlast Friday 7 days ago\nlast month\nlast month\n3 months ago\n3 months ago\n14 days ago\nlast month\nlast month\n21 days ago\nlast month\nlast Friday 7 days ago\n2 months ago\nlast month\n2 months ago\ntoday\n2 months ago\n2 months ago\nlast month\nlast month\nlast month\n2 months ago\nlast Friday 7 days ago\n3 months ago\n3 months ago\n3 months ago\n2 months ago\n2 months ago\ntoday\nlast month\n4 months ago\nlast month\nlast Friday 7 days ago\nlast month\n3 months ago\n2 months ago\n4 months ago\n4 months ago\nlast month\n4 months ago\n4 months ago\n2 months ago\nlast month\n2 months ago\n2 months ago\n2 months ago\nlast month\nlast Friday 7 days ago\nlast month\ntoday\n3 months ago\nlast Friday 7 days ago\nlast month\n21 days ago\n2 months ago\nlast month\n3 months ago\n3 months ago\n28 days ago\n3 months ago\n3 months ago\nlast month\n14 days ago\nlast month\nlast month\nlast month\n2 months ago\n2 months ago\n4 months ago\n3 months ago\ntoday\n3 months ago\n4 months ago\n3 months ago\nlast month\n2 months ago\n14 days ago\nlast Friday 7 days ago\n3 months ago\n14 days ago\nlast Friday 7 days ago\n2 months ago\n3 months ago\nlast month\nlast month\nlast Friday 7 days ago\n2 months ago\n3 months ago\n3 months ago\n2 months ago\n3 months ago\n2 months ago\n28 days ago\nlast month\nlast Friday 7 days ago\n2 months ago\ntoday\n21 days ago\nlast month\nlast month\n3 months ago\n14 days ago\n3 months ago\n2 months ago\n2 months ago\n2 months ago\nlast month\nlast month\nlast month\nlast Friday 7 days ago\n3 months ago\ntoday\nlast month\n14 days ago\n2 months ago\nlast month\n3 months ago\n3 months ago\n21 days ago\n3 months ago\n3 months ago\nlast month\nlast Friday 7 days ago\nlast month\nlast month\nlast month\n2 months ago\n3 months ago\n3 months ago\n2 months ago\n3 months ago\n2 months ago\nlast Friday 7 days ago\nlast month\n14 days ago\n2 months ago\n21 days ago\ntoday\nlast month\nlast month\n3 months ago\nlast Friday 7 days ago\n3 months ago\n21 days ago\n2 months ago\n2 months ago\nlast month\n2 months ago\n2 months ago\nlast month\n2 months ago\nlast month\nlast Friday 7 days ago\n14 days ago\nlast month\nlast month\nlast month\nlast month\ntoday\nlast Friday 7 days ago\n2 months ago\nlast month\n2 months ago\n14 days ago\n2 months ago\n2 months ago\nlast month\n2 months ago\n2 months ago\nlast month\n2 months ago\nlast month\nlast month\nlast Friday 7 days ago\nlast month\nlast month\nlast month\nlast month\nlast Friday 7 days ago\ntoday\n2 months ago\nlast month\n2 months ago\n2 months ago\n4 months ago\n4 months ago\nlast month\nlast Friday 7 days ago\nlast Friday 7 days ago\nlast month\n14 days ago\nlast month\n3 months ago\n2 months ago\n3 months ago\nlast month\n3 months ago\n3 months ago\n2 months ago\n2 months ago\ntoday\n3 months ago\n21 days ago\n3 months ago\n3 months ago\n3 months ago\n2 months ago\n2 months ago\nlast Friday 7 days ago\nlast month\n4 months ago\nlast month\ntoday\nlast month\n3 months ago\n2 months ago\n4 months ago\n4 months ago\nlast Friday 7 days ago\n4 months ago\n4 months ago\n2 months ago\nlast month\n2 months ago\n2 months ago\n2 months ago\nlast month\nlast month\nlast month\n21 days ago\n3 months ago\n14 days ago\nlast month\ntoday\n2 months ago\nlast month\n3 months ago\n3 months ago\nlast Friday 7 days ago\n3 months ago\n3 months ago\nlast month\nlast Friday 7 days ago\nlast Friday 7 days ago\n14 days ago\n21 days ago\nlast Friday 7 days ago\nlast month\n3 months ago\n2 months ago\nlast month\n2 months ago\n3 months ago\n2 months ago\ntoday\nlast month\nlast month\nlast month\n2 months ago\nlast month\nlast month\nlast month\n2 months ago\nlast month\nlast month\nlast month\n2 months ago\n3 months ago\n3 months ago\n2 months ago\n3 months ago\n2 months ago\n14 days ago\nlast month\nlast Friday 7 days ago\n2 months ago\n14 days ago\nlast Friday 7 days ago\nlast month\nlast month\n3 months ago\ntoday\n3 months ago\nlast month\nlast month\nlast month\nlast Friday 7 days ago\n14 days ago\n2 months ago\nlast month\n2 months ago\nlast month\n2 months ago\nlast month\nlast month\ntoday\n2 months ago\n2 months ago\nlast month\n2 months ago\n2 months ago\nlast Friday 7 days ago\nlast month\nlast month\nlast month\nlast Friday 7 days ago\n2 months ago\n2 months ago\n4 months ago\n3 months ago\n14 days ago\n3 months ago\n4 months ago\n3 months ago\nlast month\n2 months ago\ntoday\nlast Friday 7 days ago\n3 months ago\n28 days ago\n21 days ago\n2 months ago\n3 months ago\nlast month\nlast month\nlast month\n2 months ago\n2 months ago\n4 months ago\n3 months ago\nlast Friday 7 days ago\n3 months ago\n4 months ago\n3 months ago\nlast month\n2 months ago\nlast Friday 7 days ago\ntoday\n3 months ago\n21 days ago\n14 days ago\n2 months ago\n3 months ago\n2 months ago\n2 months ago\n2 months ago\nlast month\nlast month\nlast month\n28 days ago\n3 months ago\n21 days ago\nlast Friday 7 days ago\nlast Friday 7 days ago\n2 months ago\nlast month\n3 months ago\n3 months ago\ntoday\n3 months ago\n3 months ago\nlast month\n14 days ago\nlast month\nlast month\nlast month\n2 months ago\n2 months ago\n4 months ago\n3 months ago\n14 days ago\n3 months ago\n4 months ago\n3 months ago\nlast month\n2 months ago\n28 days ago\n21 days ago\n3 months ago\ntoday\nlast Friday 7 days ago\n2 months ago\n3 months ago\nlast month\nlast month\nlast month\n2 months ago\n2 months ago\n4 months ago\n3 months ago\nlast Friday 7 days ago\n3 months ago\n4 months ago\n3 months ago\nlast month\n2 months ago\n21 days ago\n14 days ago\n3 months ago\nlast Friday 7 days ago\ntoday\n2 months ago\n3 months ago\n2 months ago\n4 months ago\n4 months ago\nlast month\n14 days ago\n28 days ago\nlast month\nlast Friday 7 days ago\nlast month\n3 months ago\n2 months ago\n3 months ago\nlast Friday 7 days ago\n3 months ago\n3 months ago\n2 months ago\n2 months ago\n21 days ago\n3 months ago\ntoday\nlast month\nlast month\nlast month\n14 days ago\nlast Friday 7 days ago\n2 months ago\nlast month\n2 months ago\nlast month\n2 months ago\nlast month\nlast month\nlast Friday 7 days ago\n2 months ago\n2 months ago\nlast month\n2 months ago\n2 months ago\ntoday\nlast month\n2 months ago\n2 months ago\n2 months ago\nlast month\nlast month\nlast month\n14 days ago\n3 months ago\nlast Friday 7 days ago\nlast month\nlast Friday 7 days ago\n2 months ago\nlast month\n3 months ago\n3 months ago\n14 days ago\n3 months ago\n3 months ago\nlast month\ntoday\n"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "f = open(\"summary.txt\", \"a\")\n",
    "f1 = open(\"input.txt\", \"a\")\n",
    "start_date = datetime.datetime.strptime('2016-08-19', '%Y-%m-%d').date()\n",
    "end_date = datetime.datetime.strptime('2016-12-31', '%Y-%m-%d').date()\n",
    "period = Period(start_date, end_date, PeriodType.quarter)\n",
    "stock_narrator = Narrator(period)\n",
    "\n",
    "with open('export.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    for row in reader:\n",
    "        for i, _ in enumerate(row):\n",
    "            row[i] = row[i].replace(\",\", \" \")\n",
    "            row[i] = row[i].replace(' ', '_')\n",
    "        mydict_obj = StockDataDict(\n",
    "        symbol=row[0],\n",
    "        last_week_close_price='0',\n",
    "        start_ts = row[9],\n",
    "        end_ts= (datetime.datetime.strptime(row[9],\"%d_%b_%Y\") + datetime.timedelta(days = (7))).strftime(\"%d_%b_%Y\"),\n",
    "        curr_period_avg=row[1],\n",
    "        curr_period_min=row[2],\n",
    "        curr_period_max=row[3],\n",
    "        curr_period_var=row[4],\n",
    "        numeric_units=DataType.dollar,\n",
    "        company=row[5],\n",
    "        hq=row[8],\n",
    "        domain=row[6] + '(' + row[7] + ')'\n",
    "        )\n",
    "        with open('export.csv', mode='r') as infile1:\n",
    "            reader1 = csv.reader(infile1)\n",
    "            for row1 in reader1:\n",
    "                for i, _ in enumerate(row1):\n",
    "                    row1[i] = row1[i].replace(\",\", \" \")\n",
    "                    row1[i] = row1[i].replace(' ', '_')\n",
    "                mydict_obj1 = StockDataDict(\n",
    "                symbol=row1[0],\n",
    "                last_week_close_price='0',\n",
    "                start_ts = row1[9],\n",
    "                end_ts= (datetime.datetime.strptime(row1[9],\"%d_%b_%Y\") + datetime.timedelta(days = (7))).strftime(\"%d_%b_%Y\"),\n",
    "                curr_period_avg=row1[1],\n",
    "                curr_period_min=row1[2],\n",
    "                curr_period_max=row1[3],\n",
    "                curr_period_var=row1[4],\n",
    "                numeric_units=DataType.dollar,\n",
    "                company=row1[5],\n",
    "                hq=row1[8],\n",
    "                domain=row1[6] + '(' + row1[7] + ')'\n",
    "                )\n",
    "                summary = (stock_narrator.add_horzBar_chart(mydict_obj, \"\", '1 Week', mydict_obj1))\n",
    "                f.write(listToString(summary) + '\\n')\n",
    "                input_line = \"symbol_1:\"+row[0] + \" \tstartts_1:\" + row[9] + \" \tendts_1:\" + (datetime.datetime.strptime(row[9] , \"%d_%b_%Y\")  +  datetime.timedelta(days = (7))).strftime(\"%d_%b_%Y\") + \" \tcurrperiodavg_1:\"+row[1] + \" \tcurrperiodmin_1:\" + row[2] + \" \tcurrperiodmax_1:\" + row[3] + \" \tcurrperiodvar_1:\" + row[4] + \" \tnumericunits_1:$\" + \" \tcompany_1:\" + row[5] + \" \thq_1:\" + row[8] + \" \tdomain_1:\" + row[6]  + \" \tdomain_2:\" +  '('  +  \" \tdomain_3:\" + row[7]  + \" \tdomain_4:\" + ')'+\" \tsymbol_2:\"+row1[0] + \" \tstartts_2:\" + row1[9] + \" \tendts_2:\" + (datetime.datetime.strptime(row1[9] , \"%d_%b_%Y\")  +  datetime.timedelta(days = (7))).strftime(\"%d_%b_%Y\") + \" \tcurrperiodavg_2:\"+row1[1] + \" \tcurrperiodmin_2:\" + row1[2] + \" \tcurrperiodmax_2:\" + row1[3] + \" \tcurrperiodvar_2:\" + row1[4] + \" \tnumericunits_2:$\" + \" \tcompany_2:\" + row1[5] + \" \thq_2:\" + row1[8] + \" \tdomain_1:\" + row[6]  + \" \tdomain_2:\" +  '('  +  \" \tdomain_3:\" + row[7]  + \" \tdomain_4:\" + ')'\n",
    "                f1.write(input_line + '\\n')\n",
    "        \n",
    "f.close()\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}